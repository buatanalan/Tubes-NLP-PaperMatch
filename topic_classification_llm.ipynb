{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182c5e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Iskandar\\Documents\\GitHub\\Tubes-NLP-PaperMatch\\hf_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"kilian-group/arxiv-classifier\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff51202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert to pandas\n",
    "train_df = ds[\"train\"].to_pandas()\n",
    "test_df  = ds[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea86f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[[\"field\", \"abstract\"]]\n",
    "test_df  = test_df[[\"field\", \"abstract\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a3324a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>An electric current controlled spin-wave logic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>We investigate nanoelectromechanical systems n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>We have investigated the polarization dependen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>The erasure of a classical bit of information ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>While mesoscopic conducting loops are sensitiv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      field                                           abstract\n",
       "0  cond-mat  An electric current controlled spin-wave logic...\n",
       "1  cond-mat  We investigate nanoelectromechanical systems n...\n",
       "2  cond-mat  We have investigated the polarization dependen...\n",
       "3  cond-mat  The erasure of a classical bit of information ...\n",
       "4  cond-mat  While mesoscopic conducting loops are sensitiv..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566e38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(train_df['field'].unique())\n",
    "label2id = {lab: i for i, lab in enumerate(labels)}\n",
    "id2label = {i: lab for lab, i in label2id.items()}\n",
    "train_df['label_id'] = train_df['field'].map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d144e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8117e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02257d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "  text = str(text).lower()\n",
    "\n",
    "  tokens = word_tokenize(text)\n",
    "\n",
    "  tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9210cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"new_abstract\"] = train_df[\"abstract\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f6feb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"new_abstract\"] = test_df[\"abstract\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "672006b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label_id'] = test_df['field'].map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f44b6bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>abstract</th>\n",
       "      <th>label_id</th>\n",
       "      <th>new_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>An electric current controlled spin-wave logic...</td>\n",
       "      <td>1</td>\n",
       "      <td>electric current controlled spin-wave logic ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>We investigate nanoelectromechanical systems n...</td>\n",
       "      <td>1</td>\n",
       "      <td>investigate nanoelectromechanical system near ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>We have investigated the polarization dependen...</td>\n",
       "      <td>1</td>\n",
       "      <td>investigated polarization dependence generatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>The erasure of a classical bit of information ...</td>\n",
       "      <td>1</td>\n",
       "      <td>erasure classical bit information dissipative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>While mesoscopic conducting loops are sensitiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>mesoscopic conducting loop sensitive external ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      field                                           abstract  label_id  \\\n",
       "0  cond-mat  An electric current controlled spin-wave logic...         1   \n",
       "1  cond-mat  We investigate nanoelectromechanical systems n...         1   \n",
       "2  cond-mat  We have investigated the polarization dependen...         1   \n",
       "3  cond-mat  The erasure of a classical bit of information ...         1   \n",
       "4  cond-mat  While mesoscopic conducting loops are sensitiv...         1   \n",
       "\n",
       "                                        new_abstract  \n",
       "0  electric current controlled spin-wave logic ga...  \n",
       "1  investigate nanoelectromechanical system near ...  \n",
       "2  investigated polarization dependence generatio...  \n",
       "3  erasure classical bit information dissipative ...  \n",
       "4  mesoscopic conducting loop sensitive external ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63e8656c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>abstract</th>\n",
       "      <th>new_abstract</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>Proximity-induced magnetic effects on the surf...</td>\n",
       "      <td>proximity-induced magnetic effect surface dira...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>We present the first experimental microwave re...</td>\n",
       "      <td>present first experimental microwave realizati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>We report on the effect of the lateral confine...</td>\n",
       "      <td>report effect lateral confinement perpendicula...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>Measurement of gravitational Hawking radiation...</td>\n",
       "      <td>measurement gravitational hawking radiation bl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cond-mat</td>\n",
       "      <td>We study the non-equilibrium evolution of conc...</td>\n",
       "      <td>study non-equilibrium evolution concurrence be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      field                                           abstract  \\\n",
       "0  cond-mat  Proximity-induced magnetic effects on the surf...   \n",
       "1  cond-mat  We present the first experimental microwave re...   \n",
       "2  cond-mat  We report on the effect of the lateral confine...   \n",
       "3  cond-mat  Measurement of gravitational Hawking radiation...   \n",
       "4  cond-mat  We study the non-equilibrium evolution of conc...   \n",
       "\n",
       "                                        new_abstract  label_id  \n",
       "0  proximity-induced magnetic effect surface dira...         1  \n",
       "1  present first experimental microwave realizati...         1  \n",
       "2  report effect lateral confinement perpendicula...         1  \n",
       "3  measurement gravitational hawking radiation bl...         1  \n",
       "4  study non-equilibrium evolution concurrence be...         1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc48e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_df_new.csv\", index=False)\n",
    "test_df.to_csv(\"test_df_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0786a25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Iskandar\\Documents\\GitHub\\Tubes-NLP-PaperMatch\\hf_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import torch, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe23266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_map = {\n",
    "    \"bert\": \"bert-base-uncased\",\n",
    "    \"roberta\": \"roberta-base\",\n",
    "    \"distilbert\": \"distilbert-base-uncased\"\n",
    "}\n",
    "\n",
    "tokenizers = {k: AutoTokenizer.from_pretrained(v) for k, v in tokenizer_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e95ac51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108696, 4), (27178, 4))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e75cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df[\"new_abstract\"].astype(str).values,\n",
    "    train_df[\"label_id\"].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_df[\"label_id\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "673e73e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            avg_tokens  median_tokens  max_tokens  min_tokens  percent_truncated_at_{}\n",
      "bert        142.904333          132.0       788.0         9.0                      0.0\n",
      "roberta     141.450667          131.0       791.0         9.0                      0.0\n",
      "distilbert  142.904333          132.0       788.0         9.0                      0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tokenizer_stats(sample_texts, tokenizers, max_length=40, n_samples=1000):\n",
    "    sample = list(sample_texts)[:n_samples]\n",
    "    stats = {}\n",
    "    for name, tok in tokenizers.items():\n",
    "        counts = []\n",
    "        n_trunc = 0\n",
    "        for t in sample:\n",
    "            enc = tok(t, add_special_tokens=True)\n",
    "            length = len(enc[\"input_ids\"])\n",
    "            counts.append(length)\n",
    "            if length > max_length:\n",
    "                n_trunc += 1\n",
    "        stats[name] = {\n",
    "            \"avg_tokens\": float(np.mean(counts)),\n",
    "            \"median_tokens\": float(np.median(counts)),\n",
    "            \"max_tokens\": int(np.max(counts)),\n",
    "            \"min_tokens\": int(np.min(counts)),\n",
    "            \"percent_truncated_at_{}\": 100.0 * n_trunc / len(sample)\n",
    "        }\n",
    "    return stats\n",
    "\n",
    "tok_stats = tokenizer_stats(train_texts, tokenizers, max_length=200000, n_samples=min(3000, len(train_texts)))\n",
    "pd.set_option('display.width', 120)\n",
    "print(pd.DataFrame(tok_stats).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28c7842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "def prepare_hf_dataset(texts, labels, tokenizer, max_length=40):\n",
    "    ds = Dataset.from_dict({\"text\": list(texts), \"label\": list(labels)})\n",
    "    def tokenize_fn(batch):\n",
    "        return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    ds = ds.map(tokenize_fn, batched=True)\n",
    "    ds = ds.remove_columns([c for c in ds.column_names if c not in (\"input_ids\", \"attention_mask\", \"label\")])\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af556af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import evaluate\n",
    "\n",
    "metric_accuracy = evaluate.load(\"accuracy\")\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "metric_precision = evaluate.load(\"precision\")\n",
    "metric_recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "\n",
    "    acc = metric_accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    f1w = metric_f1.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    precw = metric_precision.compute(predictions=preds, references=labels, average=\"weighted\")[\"precision\"]\n",
    "    recw = metric_recall.compute(predictions=preds, references=labels, average=\"weighted\")[\"recall\"]\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": precw, \"recall\": recw, \"f1\": f1w}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0ed5a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c28f97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train = {\n",
    "    \"bert\": \"bert-base-uncased\",\n",
    "    \"roberta\": \"roberta-base\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0123276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Fine-tuning bert with LoRA (bert-base-uncased)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 605,204 || all params: 110,102,824 || trainable%: 0.5497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 86956/86956 [00:25<00:00, 3451.14 examples/s]\n",
      "Map: 100%|██████████| 21740/21740 [00:06<00:00, 3147.66 examples/s]\n",
      "C:\\Users\\Iskandar\\AppData\\Local\\Temp\\ipykernel_32108\\1269238027.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54350' max='54350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54350/54350 2:41:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.818700</td>\n",
       "      <td>0.714693</td>\n",
       "      <td>0.764259</td>\n",
       "      <td>0.749723</td>\n",
       "      <td>0.764259</td>\n",
       "      <td>0.751320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>0.657484</td>\n",
       "      <td>0.778703</td>\n",
       "      <td>0.774051</td>\n",
       "      <td>0.778703</td>\n",
       "      <td>0.773024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.592100</td>\n",
       "      <td>0.626920</td>\n",
       "      <td>0.786937</td>\n",
       "      <td>0.789634</td>\n",
       "      <td>0.786937</td>\n",
       "      <td>0.785747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.590400</td>\n",
       "      <td>0.615041</td>\n",
       "      <td>0.791720</td>\n",
       "      <td>0.791565</td>\n",
       "      <td>0.791720</td>\n",
       "      <td>0.788816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.542600</td>\n",
       "      <td>0.603629</td>\n",
       "      <td>0.798298</td>\n",
       "      <td>0.795184</td>\n",
       "      <td>0.798298</td>\n",
       "      <td>0.793480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.520200</td>\n",
       "      <td>0.620735</td>\n",
       "      <td>0.801748</td>\n",
       "      <td>0.794798</td>\n",
       "      <td>0.801748</td>\n",
       "      <td>0.794800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.458100</td>\n",
       "      <td>0.608116</td>\n",
       "      <td>0.800368</td>\n",
       "      <td>0.802468</td>\n",
       "      <td>0.800368</td>\n",
       "      <td>0.799877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.480400</td>\n",
       "      <td>0.613065</td>\n",
       "      <td>0.802070</td>\n",
       "      <td>0.798134</td>\n",
       "      <td>0.802070</td>\n",
       "      <td>0.798755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.434100</td>\n",
       "      <td>0.615886</td>\n",
       "      <td>0.803542</td>\n",
       "      <td>0.800311</td>\n",
       "      <td>0.803542</td>\n",
       "      <td>0.800609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.448500</td>\n",
       "      <td>0.620778</td>\n",
       "      <td>0.804002</td>\n",
       "      <td>0.800638</td>\n",
       "      <td>0.804002</td>\n",
       "      <td>0.801487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Iskandar\\Documents\\GitHub\\Tubes-NLP-PaperMatch\\hf_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1359' max='1359' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1359/1359 01:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for bert: {'eval_loss': 0.6207776069641113, 'eval_accuracy': 0.804001839926403, 'eval_precision': 0.8006378045311333, 'eval_recall': 0.804001839926403, 'eval_f1': 0.8014869463100291, 'eval_runtime': 88.4036, 'eval_samples_per_second': 245.918, 'eval_steps_per_second': 15.373, 'epoch': 10.0}\n",
      "LoRA model saved to: ./hf_finetune_results_lora\\bert\\lora_model\n",
      "\n",
      "============================================================\n",
      "Fine-tuning roberta with LoRA (roberta-base)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Iskandar\\Documents\\GitHub\\Tubes-NLP-PaperMatch\\hf_env\\Lib\\site-packages\\peft\\mapping_func.py:78: UserWarning: The PEFT config's `base_model_name_or_path` was renamed from 'bert-base-uncased' to 'roberta-base'. Please ensure that the correct base model is loaded when loading this checkpoint.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,195,796 || all params: 125,856,808 || trainable%: 0.9501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 86956/86956 [00:19<00:00, 4556.03 examples/s]\n",
      "Map: 100%|██████████| 21740/21740 [00:04<00:00, 4534.62 examples/s]\n",
      "C:\\Users\\Iskandar\\AppData\\Local\\Temp\\ipykernel_32108\\1269238027.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38045' max='54350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38045/54350 1:52:42 < 48:18, 5.63 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.810700</td>\n",
       "      <td>0.685060</td>\n",
       "      <td>0.766513</td>\n",
       "      <td>0.758330</td>\n",
       "      <td>0.766513</td>\n",
       "      <td>0.753315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.680400</td>\n",
       "      <td>0.643060</td>\n",
       "      <td>0.779853</td>\n",
       "      <td>0.776004</td>\n",
       "      <td>0.779853</td>\n",
       "      <td>0.775114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.630900</td>\n",
       "      <td>0.611170</td>\n",
       "      <td>0.786569</td>\n",
       "      <td>0.791824</td>\n",
       "      <td>0.786569</td>\n",
       "      <td>0.786448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.598200</td>\n",
       "      <td>0.603888</td>\n",
       "      <td>0.797148</td>\n",
       "      <td>0.794186</td>\n",
       "      <td>0.797148</td>\n",
       "      <td>0.792715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.564900</td>\n",
       "      <td>0.577379</td>\n",
       "      <td>0.806348</td>\n",
       "      <td>0.799309</td>\n",
       "      <td>0.806348</td>\n",
       "      <td>0.800410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.468300</td>\n",
       "      <td>0.585844</td>\n",
       "      <td>0.803082</td>\n",
       "      <td>0.797998</td>\n",
       "      <td>0.803082</td>\n",
       "      <td>0.796692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.469300</td>\n",
       "      <td>0.579764</td>\n",
       "      <td>0.804830</td>\n",
       "      <td>0.803974</td>\n",
       "      <td>0.804830</td>\n",
       "      <td>0.803140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1359' max='1359' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1359/1359 01:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for roberta: {'eval_loss': 0.5773788094520569, 'eval_accuracy': 0.8063477460901564, 'eval_precision': 0.7993087919329801, 'eval_recall': 0.8063477460901564, 'eval_f1': 0.8004100734877582, 'eval_runtime': 87.3598, 'eval_samples_per_second': 248.856, 'eval_steps_per_second': 15.556, 'epoch': 7.0}\n",
      "LoRA model saved to: ./hf_finetune_results_lora\\roberta\\lora_model\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import torch, os\n",
    "\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_EPOCHS = 10\n",
    "OUTPUT_BASE = \"./hf_finetune_results_lora\"\n",
    "os.makedirs(OUTPUT_BASE, exist_ok=True)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query\", \"value\"]\n",
    ")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for shortname, model_name in models_to_train.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fine-tuning {shortname} with LoRA ({model_name})\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(labels)\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    ds_train = prepare_hf_dataset(train_texts, train_labels, tokenizer, max_length=MAX_LEN)\n",
    "    ds_val   = prepare_hf_dataset(val_texts, val_labels, tokenizer, max_length=MAX_LEN)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(OUTPUT_BASE, shortname),\n",
    "        num_train_epochs=TRAIN_EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        eval_strategy=\"epoch\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-4,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        save_total_limit=2,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        load_best_model_at_end=True,\n",
    "        greater_is_better=True,\n",
    "        report_to=[]\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_val,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_res = trainer.evaluate()\n",
    "    print(f\"Eval results for {shortname}:\", eval_res)\n",
    "\n",
    "    save_dir = os.path.join(OUTPUT_BASE, shortname, \"lora_model\")\n",
    "    model.save_pretrained(save_dir)\n",
    "    tokenizer.save_pretrained(save_dir)\n",
    "    print(f\"LoRA model saved to: {save_dir}\")\n",
    "\n",
    "    results[shortname] = {\n",
    "        \"model_name\": model_name,\n",
    "        \"eval\": eval_res,\n",
    "        \"save_dir\": save_dir,\n",
    "        \"tokenizer\": tokenizer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6968d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train_fine_tune = {\n",
    "    \"distilbert\": \"distilbert-base-uncased\",\n",
    "}\n",
    "\n",
    "MAX_LEN = 200\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_EPOCHS = 10\n",
    "OUTPUT_BASE = \"./hf_finetune_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0298bfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Fine-tuning distilbert (distilbert-base-uncased)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 86956/86956 [00:23<00:00, 3689.61 examples/s]\n",
      "Map: 100%|██████████| 21740/21740 [00:05<00:00, 3842.59 examples/s]\n",
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27175' max='54350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27175/54350 45:35 < 45:35, 9.93 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693800</td>\n",
       "      <td>0.623146</td>\n",
       "      <td>0.789604</td>\n",
       "      <td>0.782832</td>\n",
       "      <td>0.789604</td>\n",
       "      <td>0.783060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.582351</td>\n",
       "      <td>0.803358</td>\n",
       "      <td>0.804867</td>\n",
       "      <td>0.803358</td>\n",
       "      <td>0.801852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.602608</td>\n",
       "      <td>0.807728</td>\n",
       "      <td>0.809451</td>\n",
       "      <td>0.807728</td>\n",
       "      <td>0.807187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.316300</td>\n",
       "      <td>0.696542</td>\n",
       "      <td>0.806394</td>\n",
       "      <td>0.804799</td>\n",
       "      <td>0.806394</td>\n",
       "      <td>0.804333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.223100</td>\n",
       "      <td>0.836809</td>\n",
       "      <td>0.805980</td>\n",
       "      <td>0.803361</td>\n",
       "      <td>0.805980</td>\n",
       "      <td>0.803787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1359' max='1359' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1359/1359 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results for distilbert: {'eval_loss': 0.8368091583251953, 'eval_accuracy': 0.8059797608095676, 'eval_precision': 0.8033607066517179, 'eval_recall': 0.8059797608095676, 'eval_f1': 0.8037871826010916, 'eval_runtime': 32.1745, 'eval_samples_per_second': 675.691, 'eval_steps_per_second': 42.238, 'epoch': 5.0}\n",
      "Model saved to: ./hf_finetune_results\\distilbert\\saved_model\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for shortname, model_name in models_to_train_fine_tune.items():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Fine-tuning {shortname} ({model_name})\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(labels))\n",
    "    ds_train = prepare_hf_dataset(train_texts, train_labels, tokenizer, max_length=MAX_LEN)\n",
    "    ds_val = prepare_hf_dataset(val_texts, val_labels, tokenizer, max_length=MAX_LEN)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(OUTPUT_BASE, shortname),\n",
    "        num_train_epochs=TRAIN_EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        eval_strategy=\"epoch\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"no\",\n",
    "        learning_rate=2e-5,\n",
    "        seed=42,\n",
    "        load_best_model_at_end=False,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        report_to=[],\n",
    "        fp16=torch.cuda.is_available()\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_val,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_res = trainer.evaluate()\n",
    "    print(f\"Eval results for {shortname}:\", eval_res)\n",
    "\n",
    "    save_dir = os.path.join(OUTPUT_BASE, shortname, \"saved_model\")\n",
    "    model.save_pretrained(save_dir)\n",
    "    tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "    print(f\"Model saved to: {save_dir}\")\n",
    "    results[shortname] = {\"model_name\": model_name, \"eval\": eval_res, \"tokenizer\": tokenizer, \"trainer\": trainer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa9bad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "=== Evaluating model: bert (bert-base-uncased) ===\n",
      "[PEFT] Loading LoRA model for bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Evaluation for bert\n",
      "Accuracy:  0.7959\n",
      "Precision: 0.7926\n",
      "Recall:    0.7959\n",
      "F1-score:  0.7920\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    astro-ph       0.92      0.86      0.89      1397\n",
      "    cond-mat       0.77      0.78      0.78      1800\n",
      "          cs       0.82      0.88      0.85      6973\n",
      "        econ       0.53      0.08      0.15       107\n",
      "        eess       0.51      0.39      0.44       747\n",
      "       gr-qc       0.57      0.67      0.61       200\n",
      "      hep-ex       0.90      0.57      0.70       200\n",
      "     hep-lat       0.79      0.86      0.83       200\n",
      "      hep-ph       0.58      0.62      0.60       200\n",
      "      hep-th       0.80      0.53      0.64       200\n",
      "        math       0.89      0.88      0.89      5800\n",
      "     math-ph       0.24      0.15      0.19       200\n",
      "        nlin       0.66      0.70      0.68       876\n",
      "     nucl-ex       0.72      0.40      0.51       200\n",
      "     nucl-th       0.56      0.62      0.59       200\n",
      "     physics       0.75      0.74      0.75      4161\n",
      "       q-bio       0.75      0.84      0.79      1566\n",
      "       q-fin       0.89      0.90      0.90      1151\n",
      "    quant-ph       0.55      0.53      0.54       200\n",
      "        stat       0.60      0.57      0.58       800\n",
      "\n",
      "    accuracy                           0.80     27178\n",
      "   macro avg       0.69      0.63      0.64     27178\n",
      "weighted avg       0.79      0.80      0.79     27178\n",
      "\n",
      "\n",
      "=== Evaluating model: roberta (roberta-base) ===\n",
      "[PEFT] Loading LoRA model for roberta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Evaluation for roberta\n",
      "Accuracy:  0.7903\n",
      "Precision: 0.7847\n",
      "Recall:    0.7903\n",
      "F1-score:  0.7847\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    astro-ph       0.89      0.88      0.89      1397\n",
      "    cond-mat       0.77      0.71      0.74      1800\n",
      "          cs       0.83      0.87      0.85      6973\n",
      "        econ       0.69      0.10      0.18       107\n",
      "        eess       0.55      0.38      0.45       747\n",
      "       gr-qc       0.57      0.64      0.60       200\n",
      "      hep-ex       0.77      0.65      0.71       200\n",
      "     hep-lat       0.89      0.73      0.80       200\n",
      "      hep-ph       0.69      0.47      0.56       200\n",
      "      hep-th       0.66      0.62      0.64       200\n",
      "        math       0.86      0.89      0.88      5800\n",
      "     math-ph       0.33      0.07      0.11       200\n",
      "        nlin       0.70      0.60      0.64       876\n",
      "     nucl-ex       0.66      0.55      0.60       200\n",
      "     nucl-th       0.57      0.70      0.63       200\n",
      "     physics       0.71      0.76      0.73      4161\n",
      "       q-bio       0.79      0.78      0.79      1566\n",
      "       q-fin       0.90      0.90      0.90      1151\n",
      "    quant-ph       0.57      0.54      0.55       200\n",
      "        stat       0.58      0.59      0.59       800\n",
      "\n",
      "    accuracy                           0.79     27178\n",
      "   macro avg       0.70      0.62      0.64     27178\n",
      "weighted avg       0.78      0.79      0.78     27178\n",
      "\n",
      "\n",
      "=== Evaluating model: distilbert (distilbert-base-uncased) ===\n",
      "[FINETUNE] Loading fine-tuned model for distilbert\n",
      "\n",
      ">>> Evaluation for distilbert\n",
      "Accuracy:  0.7878\n",
      "Precision: 0.7875\n",
      "Recall:    0.7878\n",
      "F1-score:  0.7846\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    astro-ph       0.86      0.91      0.89      1397\n",
      "    cond-mat       0.67      0.84      0.74      1800\n",
      "          cs       0.84      0.85      0.85      6973\n",
      "        econ       0.43      0.21      0.28       107\n",
      "        eess       0.53      0.37      0.43       747\n",
      "       gr-qc       0.52      0.72      0.61       200\n",
      "      hep-ex       0.88      0.53      0.66       200\n",
      "     hep-lat       0.92      0.76      0.83       200\n",
      "      hep-ph       0.55      0.70      0.62       200\n",
      "      hep-th       0.62      0.66      0.63       200\n",
      "        math       0.88      0.89      0.88      5800\n",
      "     math-ph       0.28      0.19      0.23       200\n",
      "        nlin       0.68      0.63      0.66       876\n",
      "     nucl-ex       0.71      0.50      0.59       200\n",
      "     nucl-th       0.54      0.73      0.62       200\n",
      "     physics       0.78      0.67      0.72      4161\n",
      "       q-bio       0.75      0.84      0.79      1566\n",
      "       q-fin       0.88      0.92      0.90      1151\n",
      "    quant-ph       0.53      0.51      0.52       200\n",
      "        stat       0.55      0.58      0.57       800\n",
      "\n",
      "    accuracy                           0.79     27178\n",
      "   macro avg       0.67      0.65      0.65     27178\n",
      "weighted avg       0.79      0.79      0.78     27178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert</td>\n",
       "      <td>0.795938</td>\n",
       "      <td>0.792639</td>\n",
       "      <td>0.795938</td>\n",
       "      <td>0.792033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta</td>\n",
       "      <td>0.790345</td>\n",
       "      <td>0.784680</td>\n",
       "      <td>0.790345</td>\n",
       "      <td>0.784674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>0.787843</td>\n",
       "      <td>0.787461</td>\n",
       "      <td>0.787843</td>\n",
       "      <td>0.784635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  precision    recall        f1\n",
       "0        bert  0.795938   0.792639  0.795938  0.792033\n",
       "1     roberta  0.790345   0.784680  0.790345  0.784674\n",
       "2  distilbert  0.787843   0.787461  0.787843  0.784635"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "MAX_LEN = 200\n",
    "FINETUNE_BASE = \"./hf_finetune_results\"\n",
    "LORA_BASE = \"./hf_finetune_results_lora\"\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "def load_model_auto(shortname, base_model_name):\n",
    "    finetune_path = os.path.join(FINETUNE_BASE, shortname, \"saved_model\")\n",
    "    lora_path = os.path.join(LORA_BASE, shortname, \"lora_model\")\n",
    "\n",
    "    if os.path.exists(lora_path):\n",
    "        print(f\"[PEFT] Loading LoRA model for {shortname}\")\n",
    "        base = AutoModelForSequenceClassification.from_pretrained(\n",
    "            base_model_name,\n",
    "            num_labels=len(labels)\n",
    "        )\n",
    "        model = PeftModel.from_pretrained(base, lora_path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(lora_path)\n",
    "\n",
    "    elif os.path.exists(finetune_path):\n",
    "        print(f\"[FINETUNE] Loading fine-tuned model for {shortname}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(finetune_path)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(finetune_path)\n",
    "\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Tidak menemukan model {shortname}\\nDicari di:\\n{finetune_path}\\n{lora_path}\"\n",
    "        )\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "def predict_batch(tokenizer, model, texts):\n",
    "    all_preds = []\n",
    "    for i in range(0, len(texts), BATCH_SIZE):\n",
    "        batch_texts = texts[i:i+BATCH_SIZE]\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=MAX_LEN\n",
    "        )\n",
    "        inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        batch_preds = torch.argmax(outputs.logits, dim=1).tolist()\n",
    "        all_preds.extend(batch_preds)\n",
    "    return all_preds\n",
    "\n",
    "def evaluate_model(tokenizer, model, df, text_col=\"abstract\", label_col=\"field\"):\n",
    "    true_labels = df[label_col].tolist()\n",
    "    pred_ids = predict_batch(tokenizer, model, df[text_col].tolist())\n",
    "    pred_labels = [id2label[i] for i in pred_ids]\n",
    "\n",
    "    df[\"predicted\"] = pred_labels\n",
    "    true_ids = [label2id[l] for l in true_labels]\n",
    "\n",
    "    accuracy = accuracy_score(true_ids, pred_ids)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        true_ids, pred_ids, average=\"weighted\"\n",
    "    )\n",
    "\n",
    "    report = classification_report(true_ids, pred_ids, target_names=labels)\n",
    "    return df, accuracy, precision, recall, f1, report\n",
    "\n",
    "def evaluate_models(df, models_to_train, text_col=\"abstract\", label_col=\"field\", save_folder=\"predictions\"):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    metrics_summary = []\n",
    "\n",
    "    for shortname, base_model_name in models_to_train.items():\n",
    "        print(f\"\\n=== Evaluating model: {shortname} ({base_model_name}) ===\")\n",
    "        tokenizer, model = load_model_auto(shortname, base_model_name)\n",
    "        pred_df, acc, prec, rec, f1, report = evaluate_model(\n",
    "            tokenizer, model, df.copy(), text_col=text_col, label_col=label_col\n",
    "        )\n",
    "\n",
    "        save_path = os.path.join(save_folder, f\"{shortname}_pred.csv\")\n",
    "        pred_df.to_csv(save_path, index=False)\n",
    "\n",
    "        print(f\"\\n>>> Evaluation for {shortname}\")\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall:    {rec:.4f}\")\n",
    "        print(f\"F1-score:  {f1:.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "\n",
    "        metrics_summary.append({\n",
    "            \"model\": shortname,\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"f1\": f1\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics_summary)\n",
    "\n",
    "models_to_train = {\n",
    "    \"bert\": \"bert-base-uncased\",\n",
    "    \"roberta\": \"roberta-base\",\n",
    "    \"distilbert\": \"distilbert-base-uncased\",\n",
    "}\n",
    "\n",
    "summary_df = evaluate_models(\n",
    "    test_df,\n",
    "    models_to_train,\n",
    "    text_col=\"abstract\",\n",
    "    label_col=\"field\"\n",
    ")\n",
    "\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c71f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
