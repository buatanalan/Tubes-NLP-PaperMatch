{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa251e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Iskandar\\Documents\\GitHub\\Tubes-NLP-PaperMatch\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memuat dataset dari processed_multixscience_data...\n",
      "‚úÖ Dataset berhasil dimuat!\n",
      "Dataset({\n",
      "    features: ['input_text', 'related_work'],\n",
      "    num_rows: 30369\n",
      "})\n",
      "\n",
      "Contoh Kolom Dataset: ['input_text', 'related_work']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "\n",
    "data_path = \"processed_multixscience_data\"\n",
    "\n",
    "print(f\"Memuat dataset dari {data_path}...\")\n",
    "try:\n",
    "    tokenized_datasets = load_from_disk(data_path)\n",
    "    print(\"‚úÖ Dataset berhasil dimuat!\")\n",
    "    print(tokenized_datasets)\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: Path salah. Cek kembali lokasi folder di panel 'Input' sebelah kanan.\")\n",
    "\n",
    "print(\"\\nContoh Kolom Dataset:\", tokenized_datasets.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61563a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOS_TOKEN biasanya diperlukan agar model tahu kapan harus berhenti menulis\n",
    "# Jika pakai Unsloth, biasanya sudah otomatis, tapi definisikan manual untuk aman.\n",
    "EOS_TOKEN = \"<|eot_id|>\"\n",
    "\n",
    "def format_prompt_llama3(examples):\n",
    "    # Ambil list data dari batch\n",
    "    inputs = examples[\"input_text\"]       # Context (Abstract + Refs)\n",
    "    outputs = examples[\"related_work\"]    # Ground Truth (Target)\n",
    "\n",
    "    prompts = []\n",
    "\n",
    "    # System Prompt: Instruksi peran untuk AI\n",
    "    system_msg = (\n",
    "        \"You are an academic writing assistant. \"\n",
    "        \"Write a 'Related Work' section based on the provided text. \"\n",
    "        \"The input contains the Current Abstract followed by References (marked with @cite_n). \"\n",
    "        \"Synthesize these references and highlight the novelty of the Current Abstract.\"\n",
    "    )\n",
    "\n",
    "    for input_text, output_text in zip(inputs, outputs):\n",
    "        # Struktur Llama 3 Instruct Resmi\n",
    "        text = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{system_msg}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{input_text}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{output_text}{EOS_TOKEN}\"\"\"\n",
    "\n",
    "        prompts.append(text)\n",
    "\n",
    "    # Kembalikan dalam kolom baru bernama 'text' (biasanya SFTTrainer mencari kolom ini)\n",
    "    return { \"text\": prompts }\n",
    "\n",
    "# --- CARA PAKAI ---\n",
    "# Asumsi 'tokenized_datasets' adalah HuggingFace Dataset yang sudah Anda load\n",
    "# Terapkan fungsi format_prompt_llama3 ke seluruh dataset\n",
    "formatted_datasets = tokenized_datasets.map(format_prompt_llama3, batched=True)\n",
    "# print(formatted_datasets['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._inductor' has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m max_seq_length = \u001b[32m1024\u001b[39m \u001b[38;5;66;03m# Sesuai hasil EDA Anda\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Iskandar\\Documents\\GitHub\\Tubes-NLP-PaperMatch\\.venv\\Lib\\site-packages\\unsloth\\__init__.py:80\u001b[39m\n\u001b[32m     68\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     69\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mUnsloth: Please update Unsloth and Unsloth-Zoo to the latest version!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDo this via `pip install --upgrade --force-reinstall --no-cache-dir --no-deps unsloth unsloth_zoo`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         )\n\u001b[32m     72\u001b[39m         \u001b[38;5;66;03m# if os.environ.get(\"UNSLOTH_DISABLE_AUTO_UPDATES\", \"0\") == \"0\":\u001b[39;00m\n\u001b[32m     73\u001b[39m         \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[32m     74\u001b[39m         \u001b[38;5;66;03m#         os.system(\"pip install --upgrade --no-cache-dir --no-deps unsloth_zoo\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     78\u001b[39m         \u001b[38;5;66;03m#         except:\u001b[39;00m\n\u001b[32m     79\u001b[39m         \u001b[38;5;66;03m#             raise ImportError(\"Unsloth: Please update unsloth_zoo via `pip install --upgrade --no-cache-dir --no-deps unsloth_zoo`\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth_zoo\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PackageNotFoundError:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     83\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsloth: Please install unsloth_zoo via `pip install unsloth_zoo` then retry!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     84\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Iskandar\\Documents\\GitHub\\Tubes-NLP-PaperMatch\\.venv\\Lib\\site-packages\\unsloth_zoo\\__init__.py:184\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# Log Unsloth-Zoo Utilities\u001b[39;00m\n\u001b[32m    182\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mUNSLOTH_ZOO_IS_PRESENT\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtemporary_patches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    185\u001b[39m     encode_conversations_with_harmony,\n\u001b[32m    186\u001b[39m )\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrl_environments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    188\u001b[39m     check_python_modules,\n\u001b[32m    189\u001b[39m     create_locked_down_function,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     launch_openenv,\n\u001b[32m    194\u001b[39m )\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# Top some pydantic warnings\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Iskandar\\Documents\\GitHub\\Tubes-NLP-PaperMatch\\.venv\\Lib\\site-packages\\unsloth_zoo\\temporary_patches\\__init__.py:18\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Unsloth Zoo - Utilities for Unsloth\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Copyright 2023-present Daniel Han-Chen, Michael Han-Chen & the Unsloth team. All rights reserved.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# You should have received a copy of the GNU Lesser General Public License\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# along with this program.  If not, see <https://www.gnu.org/licenses/>.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgemma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Iskandar\\Documents\\GitHub\\Tubes-NLP-PaperMatch\\.venv\\Lib\\site-packages\\unsloth_zoo\\temporary_patches\\common.py:39\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m inductor_config_source = inspect.getsource(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_inductor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m)\n\u001b[32m     41\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache(\u001b[32m1\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetermine_compile_threads\u001b[39m():\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/blob/ab2294d8289a7757a2fc321cdefac88e2b378edf/torch/_inductor/config.py#L771\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# Windows thread count = 1. See https://github.com/unslothai/unsloth-zoo/pull/187\u001b[39;00m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sys.platform == \u001b[33m\"\u001b[39m\u001b[33mwin32\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch._inductor' has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "if not hasattr(torch._inductor, \"config\"):\n",
    "    class DummyConfig:\n",
    "        pass\n",
    "    torch._inductor.config = DummyConfig()\n",
    "\n",
    "\n",
    "max_seq_length = 1024 # Sesuai hasil EDA Anda\n",
    "dtype = None # Auto detection\n",
    "load_in_4bit = True # WAJIB True untuk Kaggle\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/llama-3-8b-bnb-4bit\", # Versi 4-bit yang ringan\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "# target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "#                       \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
    "target_modules = [\"q_proj\", \"v_proj\"]\n",
    "\n",
    "# Tambahkan Adapter LoRA (Agar model bisa belajar)\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Rank\n",
    "    target_modules = target_modules,\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\", # Hemat VRAM\n",
    "    random_state = 3407,\n",
    ")\n",
    "\n",
    "print(\"Model Llama 3 8B (4-bit) siap di-train di Kaggle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20746f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "2.4.1+cu121\n",
      "2.4.1+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74337948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
